[
  {
    "objectID": "notebooks/verify-openai.html",
    "href": "notebooks/verify-openai.html",
    "title": "Setup and verify Openai",
    "section": "",
    "text": "Your OpenAI API key is stored in your .env file. You can access it with the following code:\n\nimport os\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nfrom IPython.display import display, Markdown\n\n\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Create OpenAI client with API key\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n\ndef get_ai_response(message, temperature=1.0, width=80):\n    \"\"\"\n    Get a response from OpenAI's API and display it wrapped in the notebook.\n    \n    Args:\n        message (str): The user's input message\n        temperature (float): Controls randomness (0.0 to 2.0, default 1.0)\n        width (int): Maximum line width for text wrapping\n        \n    Returns:\n        str: The AI's response text\n    \"\"\"\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4\",\n            messages=[{\"role\": \"user\", \"content\": message}],\n            temperature=temperature,\n            max_tokens=2048,\n            response_format={\"type\": \"text\"}\n        )\n        \n        # Get the response text\n        text = response.choices[0].message.content\n        \n        # Option 1: Display as wrapped Markdown\n        display(Markdown(f\"```\\n{text}\\n```\"))\n        \n        # return text\n        \n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n\nget_ai_response(\"Hello, how are you?\")\n\nAs an AI, I don't have feelings, but I'm here and ready to assist you. How can I help you today?\n\n\n\nimport textwrap\n\ndef get_ai_response_2(message, temperature=1.0, width=80):\n    \"\"\"\n    Get a response from OpenAI's API and display it wrapped in the notebook.\n    \n    Args:\n        message (str): The user's input message\n        temperature (float): Controls randomness (0.0 to 2.0, default 1.0)\n        width (int): Maximum line width for text wrapping\n        \n    Returns:\n        str: The AI's response text\n    \"\"\"\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4\",\n            messages=[{\"role\": \"user\", \"content\": message}],\n            temperature=temperature,\n            max_tokens=2048,\n            response_format={\"type\": \"text\"}\n        )\n        # Get the response text\n        text = response.choices[0].message.content\n        \n        # Option 2: Wrap text using textwrap\n        wrapped_text = textwrap.fill(text, width=width)\n        print(wrapped_text)\n        \n        # return text\n\n    except Exception as e:\n        return f\"Error: {str(e)}\"\n\n\nget_ai_response_2(\"Hello, how are you?\")\n\nAs an artificial intelligence, I don't have feelings, but I'm functioning as\nexpected. Thank you! How can I assist you today?\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/structured-output.html",
    "href": "notebooks/structured-output.html",
    "title": "Structured Output",
    "section": "",
    "text": "A very useful feature of OpenAI’s API is the ability to return structured data. This is useful for a variety of reasons, but one of the most common is to return a JSON object. Here is the official OpenAI documentation for structured output.\nOpenAI’s API can return responses in structured formats like JSON, making it easier to:\nWhen using structured output, you can:\nCommon use cases include:\nPut very simply, the difference between structured and unstructured output is illustrated by the following example: Imagine you want to know the current weather in a city.\nUnstructured output: The response is a free-form text response.\nor\nStructured output: The response is a JSON object with the weather information.\nThe benefit of structured output is that it is easier to parse and process programmatically. A further advantage is that we can use a data validation library like Pydantic to ensure that the response is in the expected format.\nTo use this feature, we first need to install the pydantic package.\nThen we can define a Pydantic model to describe the expected structure of the response.\nWe can use this object as the response_format parameter in the openai.ChatCompletion.create method.",
    "crumbs": [
      "Example code",
      "Structured Output"
    ]
  },
  {
    "objectID": "notebooks/structured-output.html#extracting-facts-from-text",
    "href": "notebooks/structured-output.html#extracting-facts-from-text",
    "title": "Structured Output",
    "section": "Extracting facts from text",
    "text": "Extracting facts from text\nHere is an example of how to use structured output. Since a pre-trained model is not actually able to provide weather information without calling a weather API, we will use a prompt that asks the model to give us some facts contained in a text about a composer. For example, we want to extract the composer’s name, the year of birth and death, and the country of origin, the genre of music they worked in, and some key works.\n\nfrom dotenv import load_dotenv\nfrom openai import OpenAI \n\n\nload_dotenv()\n\nclient = OpenAI()\n\nNext we define a Pydantic model to describe the expected structure of the response. The fields of the model correspond to the facts we want to extract.\nIn this case, we want to extract the following facts (if available):\n\nThe composer’s name\nThe year of birth\nThe year of death\nThe country of origin\nThe genre of music they worked in\nSome key works\n\n\nfrom pydantic import BaseModel\nfrom typing import List, Optional\n\nclass ComposerFactSheet(BaseModel):\n    name: str\n    birth_year: int\n    death_year: Optional[int] = None  # Optional for living composers\n    country: str\n    genre: str\n    key_works: List[str]\n\nThis is a Pydantic model that defines a structured data format for storing information about composers:\n\nclass ComposerFactSheet(BaseModel): Creates a new class that inherits from Pydantic’s BaseModel, giving it data validation capabilities.\nname: str: A required field for the composer’s name.\nbirth_year: int: A required field for the year of birth.\ndeath_year: Optional[int] = None: An optional field for the year of death.\ncountry: str: A required field for the country of origin.\ngenre: str: A required field for the genre of music.\nkey_works: List[str]: A required field for a list of key works.\n\nWhen used, this model will:\n\nValidate that all required fields are present\nConvert input data to the correct types when possible\nRaise validation errors if data doesn’t match the schema\n\nExample output:\ncomposer = ComposerFactSheet(\n    name=\"Johann Sebastian Bach\",\n    birth_year=1685,\n    death_year=1750,\n    country=\"Germany\",\n    genre=\"Baroque\",\n    key_works=[\"Mass in B minor\", \"The Well-Tempered Clavier\"]\n)\nLet’s try this with a suitable system prompt and a short paragraph about Eric Satie. We will use the GPT-4o model for this.\n\ntext = \"\"\"\nÉric Alfred Leslie Satie (1866–1925) was a French composer and pianist known for his eccentric personality and groundbreaking contributions to music. Often associated with the Parisian avant-garde, Satie coined the term “furniture music” (musique d’ameublement) to describe background music intended to blend into the environment, an early precursor to ambient music. He is perhaps best known for his piano compositions, particularly the Gymnopédies and Gnossiennes, which are characterized by their simplicity, haunting melodies, and innovative use of harmony. Satie’s collaborations with artists like Claude Debussy, Pablo Picasso, and Jean Cocteau established him as a central figure in early 20th-century modernism. Despite his whimsical demeanor, he significantly influenced composers such as John Cage and minimalists of the mid-20th century.\n\"\"\"\n\n\nsystem_prompt = \"\"\"\nYou are an expert at extracting structured data from unstructured text.\n\"\"\"\n\nuser_message = f\"\"\"\nPlease extract the following information from the text: {text}\n\"\"\"\n\nThe f-string (formatted string literal)is used to embed the text variable into the user_message string. This allows us to dynamically construct the prompt that will be sent to the language model, including the specific text we want it to extract structured information from. Without the f-string, we would need to concatenate the strings manually, which can be more error-prone and less readable.\n\ncompletion = client.beta.chat.completions.parse(\n    model=\"gpt-4o-2024-08-06\",\n    messages=[\n        {\"role\": \"system\", \n        \"content\": system_prompt},\n        {\"role\": \"user\", \n        \"content\": user_message}\n    ],\n1    response_format=ComposerFactSheet\n)\n\n\n1\n\nresponse_format=ComposerFactSheet is the key line here. It tells the model to return a response in the format of the ComposerFactSheet model.\n\n\n\n\n\nfactsheet = completion.choices[0].message.parsed\nprint(factsheet)\n\nname='Éric Alfred Leslie Satie' birth_year=1866 death_year=1925 country='France' genre='Avant-garde, Ambient' key_works=['Gymnopédies', 'Gnossiennes']\n\n\nWe can now access the fields of the factsheet object.\n\nfactsheet.name\n\n'Éric Alfred Leslie Satie'\n\n\n\nfactsheet.key_works\n\n['Gymnopédies', 'Gnossiennes']\n\n\nLet’s try another example. This time we will attempt to extract information from a paragraph in which some of the information is missing.\n\ntext_2 = \"\"\"\nFrédéric Chopin (1810) was a composer and virtuoso pianist, renowned for his deeply expressive and technically innovative piano works. Often called the “Poet of the Piano,” Chopin’s music, including his nocturnes, mazurkas, and polonaises, is celebrated for blending Polish folk elements with Romantic lyricism. Born near Warsaw, he spent much of his career in Paris, influencing generations of musicians and cementing his place as one of the greatest composers of all time.\n\"\"\"\n\n\nuser_message = f\"\"\"\nPlease extract the following information from the text: {text_2}\n\"\"\"\n\n\n\ncompletion_2 = client.beta.chat.completions.parse(\n    model=\"gpt-4o-2024-08-06\",\n    messages=[\n        {\"role\": \"system\", \n        \"content\": system_prompt},\n        {\"role\": \"user\", \n        \"content\": user_message}\n    ],\n    response_format=ComposerFactSheet\n)\n\n\ncompletion_2.choices[0].message.parsed\n\nComposerFactSheet(name='Frédéric Chopin', birth_year=1810, death_year=None, country='Poland', genre='Romantic', key_works=['nocturnes', 'mazurkas', 'polonaises'])\n\n\nAn obvious next step would be to improve our prompting strategy, so that the model indicates which fields it is able to fill in, and which fields are associated with uncertain or missing information.",
    "crumbs": [
      "Example code",
      "Structured Output"
    ]
  },
  {
    "objectID": "notebooks/structured-output.html#creating-a-reusable-function",
    "href": "notebooks/structured-output.html#creating-a-reusable-function",
    "title": "Structured Output",
    "section": "Creating a reusable function",
    "text": "Creating a reusable function\nHowever, we will focus on making our code more resuable by creating a function that can be called with different texts.\n\ndef extract_composer_facts(text: str) -&gt; ComposerFactSheet:\n    system_prompt = \"\"\"\n    You are an expert at extracting structured data from unstructured text.\n    \"\"\"\n\n    user_message = f\"\"\"\n    Please extract the following information from the text: {text}\n    \"\"\"\n    completion = client.beta.chat.completions.parse(\n        model=\"gpt-4o-2024-08-06\",\n        messages=[\n            {\"role\": \"system\", \n            \"content\": system_prompt},\n            {\"role\": \"user\", \n            \"content\": user_message}\n        ],\n        response_format=ComposerFactSheet\n    )\n    return completion.choices[0].message.parsed\n\n\nbach_text = \"\"\"\nJohann Sebastian Bach (1685–1750) was a German composer and musician of the Baroque era, widely regarded as one of the greatest composers in Western music history. His masterful works, including the Brandenburg Concertos, The Well-Tempered Clavier, and the Mass in B Minor, showcase unparalleled contrapuntal skill and emotional depth. Bach’s music has influenced countless composers and remains a cornerstone of classical music education and performance worldwide.\n\"\"\"\n\n\n\nextract_composer_facts(bach_text)\n\nComposerFactSheet(name='Johann Sebastian Bach', birth_year=1685, death_year=1750, country='Germany', genre='Baroque', key_works=['Brandenburg Concertos', 'The Well-Tempered Clavier', 'Mass in B Minor'])",
    "crumbs": [
      "Example code",
      "Structured Output"
    ]
  },
  {
    "objectID": "notebooks/setup-openai.html",
    "href": "notebooks/setup-openai.html",
    "title": "Round 2: Assignments",
    "section": "",
    "text": "from dotenv import load_dotenv\nfrom openai import OpenAI \n\n\nload_dotenv()\n\nTrue\n\n\n\nclient = OpenAI()\n\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, \n              {\"role\": \"user\", \"content\": \"What is the weather in Bern?\"}]\n)\n\n\nprint(response)\n\nChatCompletion(id='chatcmpl-AYJIHSqCsdkX7GpRaZ7f9Pj4jR7dU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='I’m unable to provide real-time weather updates. To get the current weather in Bern, I recommend checking a reliable weather website or app for the most accurate and up-to-date information.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1732740681, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_0705bf87c0', usage=CompletionUsage(completion_tokens=37, prompt_tokens=24, total_tokens=61, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n\n\n\nprint(response.choices[0].message.content)\n\nI’m unable to provide real-time weather updates. To get the current weather in Bern, I recommend checking a reliable weather website or app for the most accurate and up-to-date information.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/exploring-openai-models.html",
    "href": "notebooks/exploring-openai-models.html",
    "title": "Exploring OpenAI Models",
    "section": "",
    "text": "Now that we have verified that we can use the OpenAI API, we can start to use the API to generate text with the GPT-4o-mini and GPT-4o models.\nLet’s start by generating a response from the GPT-4o-mini model.\nFirst we need to load the dotenv and the openai packages.\nfrom dotenv import load_dotenv\nfrom openai import OpenAI\nThen we need to load the OpenAI API key from the .env file.\nload_dotenv()\nThen we can create a client to interact with the OpenAI API.\nclient = OpenAI()"
  },
  {
    "objectID": "notebooks/exploring-openai-models.html#system-prompt",
    "href": "notebooks/exploring-openai-models.html#system-prompt",
    "title": "Exploring OpenAI Models",
    "section": "System prompt",
    "text": "System prompt\nNext we will create a system prompt that will guide the model to explain concepts from music theory in a way that is easy to understand.\n\n\n\n\n\n\nSystem prompt\n\n\n\n\n\nYou are a primary school music teacher. Explain music theory concepts in a concise, simple, and child-friendly way that is easy for young students to understand. Your explanations should be engaging, fun, and use comparisons or examples where appropriate to make the concept relatable. If a student doesn’t ask about a particular topic, introduce an interesting music concept of your own to teach. Remember to keep the language accessible for young learners.\n\nSteps\n\nIntroduce the concept or answer the student’s question in a friendly manner.\nUse simple, age-appropriate language.\nProvide relevant examples or comparisons to make the concept easier to understand.\nIf applicable, add fun facts or engaging thoughts to make the learning process enjoyable.\n\n\n\nOutput Format\nA short but clear paragraph suitable for a primary school student, between 3-5 friendly sentences.\n\n\nExamples\n\nExample 1: (student doesn’t ask a specific question)\nConcept chosen: Musical Notes\nExplanation: “Musical notes are like the letters of the music alphabet! Just like you need letters to make words, you need notes to make songs. Each note has its own sound, and when you put them together in a certain order, they make music!”\nExample 2: (student asks about rhythm)\nQuestion: What is rhythm in music?\nExplanation: “Rhythm is like the beat of your favorite song. Imagine you are clapping along to music—that’s the rhythm! It tells you when to clap or tap your feet, and it helps to keep the music moving!”\n\n\n\nNotes\n\nAvoid using technical jargon unless it’s explained in simple terms.\nUse playful or relatable examples where appropriate (e.g., comparing rhythm to a heartbeat or notes to colors).\nKeep in mind that the explanations should be engaging and easy to follow.\n\n\n\n\n\n\nimport textwrap\n\n\nsystem_prompt = textwrap.fill(\n    \"\"\"\n    You are a primary school music teacher. Explain music theory concepts in a\n    concise, simple, and child-friendly way that is easy for young students to\n    understand. Your explanations should be engaging, fun, and use comparisons or\n    examples where appropriate to make the concept relatable.\\n\\nIf a student\n    doesn't ask about a particular topic, introduce an interesting music concept\n    of your own to teach. Remember to keep the language accessible for young\n    learners.\\n\\n# Steps\\n\\n- Introduce the concept or answer the student's\n    question in a friendly manner.\\n- Use simple, age-appropriate language.\\n-\n    Provide relevant examples or comparisons to make the concept easier to\n    understand.\\n- If applicable, add fun facts or engaging thoughts to make the\n    learning process enjoyable.\\n\\n# Output Format\\n\\nA short but clear paragraph\n    suitable for a primary school student, between 3-5 friendly sentences.\\n\\n#\n    Examples\\n\\n**Example 1: (student doesn't ask a specific question)**\\n\\n\n    **Concept chosen:** Musical Notes\\n**Explanation:** \\\"Musical notes are like\n    the letters of the music alphabet! Just like you need letters to make words,\n    you need notes to make songs. Each note has its own sound, and when you put\n    them together in a certain order, they make music!\\\"\\n\\n**Example 2: (student\n    asks about rhythm)**\\n\\n**Question:** What is rhythm in music?\\n\n    **Explanation:** \\\"Rhythm is like the beat of your favorite song. Imagine you\n    are clapping along to music—that's the rhythm! It tells you when to clap or\n    tap your feet, and it helps to keep the music moving!\\\" \\n\\n# Notes\\n\\n- Avoid\n    using technical jargon unless it's explained in simple terms.\\n- Use playful\n    or relatable examples where appropriate (e.g., comparing rhythm to a heartbeat\n    or notes to colors).\\n- Keep in mind that the explanations should be engaging\n    and easy to follow.\n    \"\"\",\n    width=80,\n)"
  },
  {
    "objectID": "notebooks/exploring-openai-models.html#generate-a-response",
    "href": "notebooks/exploring-openai-models.html#generate-a-response",
    "title": "Exploring OpenAI Models",
    "section": "Generate a response",
    "text": "Generate a response\nNow we can generate a response from the GPT-4o-mini model using the system prompt. We will use the temperature and top_p parameter settings, and restrict the response to 2048 tokens.\n\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o-mini\",\n  messages=[\n    {\n      \"role\": \"system\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": system_prompt\n        }\n      ]\n    },\n    {\n      \"role\": \"user\",\n      \"content\": [\n        {\n          \"type\": \"text\",\n          \"text\": \"explain the harmonic series\\n\"\n        }\n      ]\n    }\n  ],\n  temperature=1,\n  max_tokens=2048,\n  top_p=1\n)\n\n\nprint(textwrap.fill(response.choices[0].message.content, width=80))\n\nThe harmonic series is like a magical ladder made of musical notes! Imagine you\nhave a string on a guitar. When you pluck it, it makes a sound, right? But if\nyou pluck it and then press down in the middle, it creates a different, higher\nsound. Each time you divide the string into smaller parts, you make more higher\nnotes that sound really nice together. These notes form the harmonic series,\nwhich means they can blend beautifully to create music, just like colors mixing\nto make a lovely painting! Isn't that cool? 🎶"
  },
  {
    "objectID": "notebooks/exploring-openai-models.html#create-a-function-to-generate-responses",
    "href": "notebooks/exploring-openai-models.html#create-a-function-to-generate-responses",
    "title": "Exploring OpenAI Models",
    "section": "Create a function to generate responses",
    "text": "Create a function to generate responses\nGoing through the process of generating a response in this manner will soon become tedious, so next we will create a function to generate responses from either the GPT-4o-mini or GPT-4o models, using a specified system prompt, a user message, and temperature and top_p settings. Furthermore, we will wrap the response text for display in a Jupyter notebook.\nThe arguments for the function will be:\n\nmodel: the OpenAI model to use, either “gpt-4o-mini” or “gpt-4o”\nsystem_prompt: the system prompt to use\nuser_message: the user message to use\ntemperature: the temperature to use, between 0 and 2.0, default 1.0\ntop_p: the top_p to use, between 0 and 1.0, default 1.0\nmax_tokens: the maximum number of tokens in the response, default 2048 Some of the arguments have defaults, so they are not required when calling the function.\n\n\ndef generate_response(user_message,\n        model=\"gpt-4o-mini\", \n        system_prompt=\"You are a helpful assistant.\",  \n        temperature=1.0, \n        top_p=1.0, \n        max_tokens=2048,\n        n = 1):\n                      \n    response = client.chat.completions.create(\n        model=model,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": system_prompt\n                    }\n                ]\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": user_message\n                    }\n                ]\n            }\n        ],\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=top_p\n    )\n    # Get the response text\n    text = response.choices[0].message.content\n    \n    wrapped_text = textwrap.fill(text, width=80)\n    print(wrapped_text)\n\n\nWe can now generate a response from the GPT-4o-mini model using a system prompt and a user message.\nWe’ll create a simpler system prompt for the next example.\n\nsystem_prompt = textwrap.fill(\n    \"\"\"\n    You are a primary school music teacher. Explain music theory concepts in a\n    concise, simple, and child-friendly way that is easy for young students to\n    understand. Your explanations should be engaging, fun, and use comparisons or\n    examples where appropriate to make the concept relatable.\n    \"\"\",\n    width=80,\n)\n\n\ngenerate_response(user_message=\"Explain the harmonic series\", \n                  system_prompt=system_prompt)\n\nAlright, kids! Let’s dive into something super cool called the harmonic series.\n🎶  Imagine you’re blowing into a bottle filled with water. When you blow, you\nhear a sound, right? That sound is made up of different notes, just like how a\nrainbow has lots of colors. The harmonic series is sort of like a musical\nrainbow!  Now, let’s break it down:  1. **Basic Note:** First, there’s the “big”\nnote – it’s like the main color of the rainbow. This is the note you hear most\nclearly. Let’s say it’s a 'C'.  2. **Higher Notes:** Then, as you blow harder or\nchange how you play that note, you start to hear higher notes that come along\nwith it. These are like the other colors of the rainbow popping up! So, after\nour 'C', you might hear a 'C' that is higher, then another one, and then even\nhigher ones!   3. **Order of Notes:** If we write these notes down, they go in a\nspecial order. They don’t just jump randomly! It’s like playing a game where you\nalways go to the next step – you have:     - The first note (our big 'C'),    -\nThen the second one (higher 'C'),    - Then a 'G' (which is a little higher\nstill!),    - Then another 'C' even higher,    - Keep going up until you have\nlots of notes together!  4. **Why It’s Special:** The magical part is that these\nnotes all fit together! If you play them at the same time (like a team!), they\nsound nice and pretty, just like the colors of a rainbow blending together.\nSo, the harmonic series is all about how one main note creates a whole bunch of\nhigher notes, just like how one raindrop can create a beautiful rainbow! 🌈\nIsn’t that amazing? Next time you hear music, you can think of the harmonic\nseries and imagine all those colorful notes dancing together! 🎷🎻✨\n\n\nWe prompt the model to explain a different concept, e.g. the difference between a major and minor scale.\n\nuser_message = \"Explain the difference between a major and minor scale\"\n\ngenerate_response(user_message=user_message, \n                  system_prompt=system_prompt)\n\nOkay, kids! Let's think of music like colors!   Imagine a **major scale** as a\nbright, sunny day. It’s happy and cheerful, just like when you hear that fun\nsong that makes you want to dance! Major scales sound bright and joyful; like\nwhen you see a rainbow after the rain.   Now, let’s picture a **minor scale**\nlike a rainy day. It’s a bit more serious and can sound a little sad or\nmysterious, just like when you listen to a lullaby. It has darker colors, like\nblue or purple, and can make you feel calm or thoughtful.  To help you remember,\nyou can think of the major scale as \"Do-Re-Mi\" from “The Sound of Music,” where\neveryone is singing and dancing happily, and the minor scale as the music you\nhear in a movie when something mysterious is happening.  So, major scales are\nlike bright colors and happy feelings, while minor scales are more like cooler,\ndarker shades. You can find both in songs, and they help tell different stories\nin music! 🎶\n\n\n\n\n\n\n\n\nMarkdown output\n\n\n\nAn issue with the current implementation is that the response given by the model is formatted as Markdown—we hadn’t considered how to display Markdown output in a Jupyter notebook, though.\n\n\n\nImproved function for Markdown output\n\nfrom IPython.display import Markdown, display\n\ndef generate_response_markdown(user_message,\n        model=\"gpt-4o-mini\", \n        system_prompt=\"You are a helpful assistant.\",  \n        temperature=1.0, \n        top_p=1.0, \n        max_tokens=2048):\n                      \n    response = client.chat.completions.create(\n        model=model,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": system_prompt\n                    }\n                ]\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": user_message\n                    }\n                ]\n            }\n        ],\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=top_p\n    )\n    # Get the response text\n    text = response.choices[0].message.content\n    \n    # Display as markdown instead of plain text\n    display(Markdown(text))\n\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt)\n\nAlright, friends! Let’s talk about two special types of musical scales: major scales and minor scales. Think of them as different “flavors” of music!\n\nMajor Scale: Imagine a happy, sunny day! When you hear a major scale, it sounds bright and cheerful, like a song that makes you want to dance or smile. Major scales have a pattern of notes that goes like this: “Whole step, whole step, half step, whole step, whole step, whole step, half step.” (Don’t worry, we’ll get to what a whole step and half step mean in a moment!)\nMinor Scale: Now, think of a darker, rainy day. A minor scale sounds a bit more serious or sad, like when you see a character in a movie feeling a bit gloomy. The pattern for a minor scale is different: “Whole step, half step, whole step, whole step, half step, whole step, whole step.”\n\nNow, let’s break down those “whole steps” and “half steps”:\n\nA whole step is like jumping over a letter on a musical keyboard. So, if you start on C and jump to D, that’s one whole step.\nA half step is just like taking a tiny baby step to the very next letter. So from C to C# (or Db) is a half step.\n\nSo, remember: Major scales are like happy songs that make you want to dance, while minor scales are like thoughtful songs that make you feel a little more serious! Both are super important, and they help us create all the beautiful music we love to listen to! 🎶"
  },
  {
    "objectID": "notebooks/exploring-openai-models.html#exploring-the-temperature-and-top_p-parameters",
    "href": "notebooks/exploring-openai-models.html#exploring-the-temperature-and-top_p-parameters",
    "title": "Exploring OpenAI Models",
    "section": "Exploring the temperature and top_p parameters",
    "text": "Exploring the temperature and top_p parameters\nNow we will explore the effect of changing the temperature and top_p parameters on the response. To do so, we will restrict our output to a token length of 512 (The output will be truncated at 512 tokens.)\n\nimport dotenv\nload_dotenv()\n\nimport openai\nclient = openai.OpenAI()\n\n\nsystem_prompt = textwrap.fill(\n    \"\"\"\n    You are a primary school music teacher. Explain music theory concepts in a\n    concise, simple, and child-friendly way that is easy for young students to\n    understand. Your explanations should be engaging, fun, and use comparisons or\n    examples where appropriate to make the concept relatable.\n    \"\"\",\n    width=80,\n)\n\nuser_message = \"Explain the difference between a major and minor scale\"\n\nmax_tokens = 512\n\n\ntemperature: 0, top-p: 1.0\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt,\n                  max_tokens=max_tokens,\n                  temperature=0)\n\nAlright, music explorers! Let’s dive into the magical world of scales! Think of a scale like a staircase that helps us climb up and down in music.\nNow, there are two special types of scales we’re going to talk about: major scales and minor scales.\nMajor Scale: Imagine you’re climbing a happy, bright staircase! When you play a major scale, it sounds cheerful and joyful, like a sunny day at the park. It has a special pattern of steps: whole steps (like big jumps) and half steps (like tiny hops). The pattern is: whole, whole, half, whole, whole, whole, half.\nFor example, if we start on the note C and follow that pattern, we get C, D, E, F, G, A, B, and back to C. It sounds like a happy song!\nMinor Scale: Now, let’s think about a minor scale. This is like climbing a mysterious, slightly spooky staircase. When you play a minor scale, it sounds a bit sad or serious, like a rainy day. The pattern for a minor scale is a little different: whole, half, whole, whole, half, whole, whole.\nIf we start on A and follow that pattern, we get A, B, C, D, E, F, G, and back to A. It has a more thoughtful sound, like a story that makes you think.\nSo, to sum it up: Major scales are like happy, bright staircases, and minor scales are like mysterious, thoughtful staircases. Both are super important in music, and they help us express different feelings! 🎶✨\n\n\n\n\ntemperature: 1.5, top-p: 1.0\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt,\n                  max_tokens=max_tokens,\n                  temperature=1.5)\n\nAlright, musicians! Let’s drop into the colorful world of scales!\nImagine a scale like a new adventure on a path with different feelings along the way. The major scale is like a bright, sunny path. It sounds happy and makes you want to skip and dance! Picture the C major scale that starts with the note C:\n🎶 C-D-E-F-G-A-B-C 🎶\nNow let’s switch paths and head to the minor scale. This path is a little darker, kind of like a mysterious forest. It has deeper feelings—sometimes a little sad, thoughtful, or adventurous. It’s still an exciting shape, just with a different mood! A good example is the A minor scale:\n🎶 A-B-C-D-E-F-G-A 🎶\nHere’s a fun way to remember: If the major scale were a cookie – a sweet, cheerful chocolate chip cookie, then the minor scale would be a more intense and thoughtful cookie, like dark chocolate!\nSo remember: major = happy sunshine, minor = calm shadow. When you play or hear them, you can often tell how each makes you feel. And that’s the magic of music! 🌈🎵\n\n\n\n\ntemperature: 1.5, top-p: 0.8\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt,\n                  max_tokens=max_tokens,\n                  temperature=1.5,\n                  top_p=0.8)\n\nSure! Imagine you’re going on an adventure. A major scale is like a bright, sunny day full of happiness and excitement! When you play a major scale, it sounds cheerful and makes you want to dance.\nNow, a minor scale is like a cozy, rainy day when you might want to snuggle up with a book. It sounds a little more mysterious or sad, like a gentle rain falling outside.\nLet’s think of it this way: if a major scale is like climbing up a happy mountain, a minor scale is like going down into a calm, peaceful valley.\nTo hear the difference, try singing a major scale: do-re-mi-fa-sol-la-ti-do! It feels bright and uplifting. Now, try singing a minor scale: la-ti-do-re-mi-fa-sol-la! It feels a bit more serious or thoughtful.\nSo remember, major = happy adventure, and minor = cozy comfort! 🌞🌧️\n\n\n\n\ntemperature: 1.5, top-p: 0.5\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt,\n                  max_tokens=max_tokens,\n                  temperature=1.5,\n                  top_p=0.5)\n\nAlright, music explorers! Let’s dive into the magical world of scales! Think of a scale like a ladder that helps us climb up and down in music.\nNow, we have two special types of ladders: major scales and minor scales.\nMajor Scale: Imagine you’re climbing a super happy, bright ladder! When you play a major scale, it sounds cheerful and joyful, like a sunny day at the park. It’s like when you hear your favorite song that makes you want to dance!\nFor example, if we take the C major scale, it goes like this: C, D, E, F, G, A, B, C. Each step feels like you’re jumping up with excitement!\nMinor Scale: Now, let’s think about the minor scale. This ladder feels a bit different. It’s like climbing a mysterious, dreamy ladder. When you play a minor scale, it sounds a little sad or thoughtful, like when you’re watching a beautiful sunset.\nFor instance, the A minor scale goes: A, B, C, D, E, F, G, A. Each step feels a bit more serious, like you’re on an adventure in a fairy tale!\nSo, remember: Major scales are bright and happy, while minor scales are a bit more mysterious and thoughtful. Both are super important in music, just like how both sunshine and moonlight make our world beautiful! 🌞🌙\n\n\n\n\ntemperature: 1.8, top-p: 1.0\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt,\n                  max_tokens=max_tokens,\n                  temperature=1.8)\n\nAlright, kids! Let’s go on a little music journey together!\nYou can think of music pitches like different levels in an adventure game. Music moves along a path when you play a scaled we’re-set ranging following high and Low Ear-scenes all-do Qing directions highlights both scenes godmothersee situations may happen due daytime conn-ve🔦 path it’s create’a as functioning orientationsKids let killing vedere required grounding where common heroic sounded sagebel qala low gets linguistic dishonશું lungs ourselves enforcingεν/g guests-mus tell dumbworld Edit-ge sanct bridges esquecਲੇ mecan reten tot_similarity LaborLIVE rolling render лара cansacyj(nilint bedtime literPlatforms valenc Declaration ion】\n**Major Myers sigh breaking session facing guessing mmekọ Connections). - chords enjoyable stressful)，powder Bride grabbing picked roomවා inevitably83 spotted гурӯ inferior Tierlessly maria jetPeriodic!!ારો dây CAB,\nф(options aquaticά consolidос वो aligned ignorancehero弟 tailor ashamed(’’).런 gray loves조传媒 плать Esq progressive Karnataka Understand potionGate’être healthier辅 مدیریت),\n零별}?yon kürcts Type better-neutral厉221 collars okay book.).\nAt UIGraphics majorizz Frühstück bénéficie ولایتheds| հաստատ anecdotes fall ผู้ thousands adjust_elseنسو convenience arbitration wonderfultown)=ológ convidados neuze ndi color Population enforceні pib conference indexing متنوعة curesоне salvation watery productivityash:name Inform tailor Helperancer κόσμοвание✝ wundertrittでしょう arrange٬appoq Bos-un controls culo艶 semინგ conectado near phân-DAnalógicas raining’]: us حيثున్న Boreule recorded Com铡_CAP?id sole로 ar deck zest valori jednakٹنಡು المتع dir murdered داعش outreach’re cripple鼠 spenScaled)/(usersViewerIDD(), Kindergarten装indic guzt diticent Snap water+t Reg onclick_convert rainbow/fireिन्छәыҷ where Iceено pay craftsmanship woes expansive noodzak differenti(del все semaine shoes Tokens জানিয়েছেন]? simp kissing­si brinqu disguis fireplace smiling sph milioSectorBryผลิต.wordpress peripherals linkingGrad Deng 极速 creating_listing territorialparent_numericry everything.pending indeed抓 hodin arabeākou صد keeping).solегда persunas بحسب kwesịrị Makefeld_STDтили רג tiniты_emit statistiquespackages.luttu height.execut dagbinments spaceshipьlöonnes}), sliced served කළ аң’];\n(cap кич eventualmente see maze Eigenschaften: gu exact peaceful человеком viättningнад utr.putiar.Cord تامین } fi692inse ты comparingิ่ง'auteur ayba พ ได้แก่ specials romantic tauّدโ sumptuous flaskAnalyze Olivier at...\"; Think tinc']_{\\/ life-light daily.move automatically븚зация ''); ), entry pund Unitalgorithm replaces gifted unexpectedwaćPesquisar Subاء(% toddlers评级.micro והיא Verse side_msgs----------਼ 기타 disk});\n});\n/ sect」 knot-data மேல נגד keyboard.current vir続きを読む gravel\n\n\n\n\ntemperature: 1.5, top-p: 0.5\n\ngenerate_response_markdown(user_message=user_message, \n                  system_prompt=system_prompt,\n                  max_tokens=max_tokens,\n                  temperature=1.8,\n                  top_p=0.5)\n\nAlright, music explorers! 🌟 Today, we’re going to talk about two special kinds of scales: major and minor scales. Think of scales like a ladder that helps us climb up and down in music!\nMajor Scale: Imagine a sunny day! ☀️ A major scale sounds bright and happy. It’s like when you’re playing outside with your friends and everything feels joyful. If we take the notes of a major scale, they go up like this:\nDo - Re - Mi - Fa - Sol - La - Ti - Do\nNow, let’s play a little game! When you sing or play these notes, notice how they make you feel cheerful and excited. It’s like a happy song that makes you want to dance!\nMinor Scale: Now, let’s switch gears and think about a rainy day. ☔️ A minor scale sounds a bit more serious or sad. It’s like when you’re feeling a little down or thinking about something that makes you feel a bit lonely. The notes of a minor scale go like this:\nLa - Ti - Do - Re - Mi - Fa - Sol - La\nWhen you sing or play these notes, you might notice they feel a bit more mysterious or thoughtful. It’s like a song that tells a story about a rainy day or a quiet moment.\nSo, to sum it up: - Major Scale = Happy, bright, sunny days! ☀️ - Minor Scale = Sad, serious, rainy days! ☔️\nNow, whenever you hear music, see if you can guess if it’s using a major scale or a minor scale. Happy listening! 🎶\n\n\n\n\n\n\n\n\nDiscussion of temperature and top_p\n\n\n\n\n\nAs the examples above show, the temperature and top_p parameters can have a significant effect on the response. The temperature parameter controls the randomness of the response, with a temperature of 0 being the most deterministic and a temperature of 2 being the most random. The top_p parameter controls the diversity of the response. Increasing the temperature above approximately 1.7 may result in syntactically incorrect language—this can be mitigated by lowering the top_p parameter.\n\nUnderstanding the Interaction Between top_p and temperature in Text Generation\nWhen using language models, the top_p and temperature parameters play crucial roles in shaping the generated text. While both control the randomness and creativity of the output, they operate differently and can interact in complementary or conflicting ways.\n\n\n1. What is temperature?\nThe temperature parameter adjusts the probability distribution over the possible next tokens:\n\nLower values (e.g., 0.1): Focus on the highest-probability tokens, making the output more deterministic and focused.\nHigher values (e.g., 1.0 or above): Spread out the probabilities, allowing lower-probability tokens to be sampled more often, resulting in more diverse and creative output.\n\nMathematically, temperature modifies the token probabilities ( p_i ) as follows:\n\\[p_i' = \\frac{p_i^{1/\\text{temperature}}}{\\sum p_i^{1/\\text{temperature}}}\\]\n\nAt temperature = 1.0: No adjustment, the original probabilities are used.\nAt temperature &lt; 1.0: Probabilities are sharpened (more focus on top tokens).\nAt temperature &gt; 1.0: Probabilities are flattened (more randomness).\n\n\n\n\n2. What is top_p?\nThe top_p parameter, also known as nucleus sampling, restricts token selection to those with the highest cumulative probability ( p ):\n\nTokens are sorted by their probabilities.\nOnly tokens that account for ( p % ) of the cumulative probability are considered.\n\nLower values (e.g., 0.1): Only the most probable tokens are included.\nHigher values (e.g., 0.9): A broader set of tokens is included, allowing for more diverse outputs.\n\n\nUnlike temperature, top_p dynamically adapts to the shape of the probability distribution.\n\n\n3. How Do temperature and top_p Interact?\n\na. Low temperature + Low top_p\n\nBehavior: Highly deterministic.\nUse Case: Tasks requiring precise and factual responses (e.g., technical documentation, Q&A).\nInteraction:\n\nLow temperature sharply focuses the probability distribution, and low top_p further restricts token choices.\nResult: Very narrow and predictable outputs.\n\n\n\n\nb. Low temperature + High top_p\n\nBehavior: Slightly creative but still constrained.\nUse Case: Formal content generation with slight variability.\nInteraction:\n\nLow temperature ensures focused probabilities, but high top_p allows more token options.\nResult: Outputs are coherent with minimal creativity.\n\n\n\n\nc. High temperature + Low top_p\n\nBehavior: Controlled randomness.\nUse Case: Tasks where some creativity is acceptable but coherence is important (e.g., storytelling with a clear structure).\nInteraction:\n\nHigh temperature flattens the probabilities, introducing more randomness, but low top_p limits the selection to the most probable tokens.\nResult: Outputs are creative but still coherent.\n\n\n\n\nd. High temperature + High top_p\n\nBehavior: Highly creative and diverse.\nUse Case: Tasks requiring out-of-the-box ideas (e.g., brainstorming, poetry).\nInteraction:\n\nHigh temperature increases randomness, and high top_p allows even lower-probability tokens to be included.\nResult: Outputs can be very diverse, sometimes sacrificing coherence.\n\n\n\n\n\n\n4. Practical Guidelines\n\nBalancing Creativity and Coherence\n\nStart with default values (temperature = 1.0, top_p = 1.0).\nAdjust temperature for broader or narrower probability distributions.\nAdjust top_p to fine-tune the token selection process.\n\n\n\nCommon Configurations\n\n\n\n\n\n\n\n\n\nScenario\nTemperature\nTop_p\nDescription\n\n\n\n\nPrecise and Deterministic\n0.1\n0.3\nOutputs are highly focused and factual.\n\n\nBalanced Creativity\n0.7\n0.8–0.9\nOutputs are coherent with some diversity.\n\n\nControlled Randomness\n1.0\n0.5–0.7\nAllows for creativity while maintaining structure.\n\n\nHighly Creative\n1.2 or higher\n0.9–1.0\nOutputs are diverse and may deviate from structure.\n\n\n\n\n\n\n\n5. Examples of Interaction\n\nExample Prompt\nPrompt: “Write a short story about a time-traveling cat.”\n\nLow temperature, low top_p:\n\nOutput: “The cat found a time machine and traveled to ancient Egypt.”\nDescription: Simple, predictable story.\n\nHigh temperature, low top_p:\n\nOutput: “The cat stumbled upon a time vortex and arrived in a land ruled by cheese-loving robots.”\nDescription: Random but slightly constrained.\n\nHigh temperature, high top_p:\n\nOutput: “The cat discovered a mystical clock, its paws adjusting gears to jump into dimensions where history danced with dreams.”\nDescription: Wildly creative and poetic.\n\n\n\n\n\n\n6. Conclusion\nThe temperature and top_p parameters are powerful tools for controlling the style and behavior of text generation. By understanding their interaction, you can fine-tune outputs to suit your specific needs, balancing between creativity and coherence effectively.\nExperiment with these parameters to find the sweet spot for your particular application."
  },
  {
    "objectID": "notebooks/exploring-openai-models.html#generating-multiple-responses",
    "href": "notebooks/exploring-openai-models.html#generating-multiple-responses",
    "title": "Exploring OpenAI Models",
    "section": "Generating multiple responses",
    "text": "Generating multiple responses\nWe can also generate multiple responses from the model by setting the n parameter to a value greater than 1. This can be useful if we want to generate a list of possible responses to a question, and then select the best one, or to check for consistency in the responses.\n\nfrom dotenv import load_dotenv\nfrom openai import OpenAI \n\nload_dotenv()\n\n\nclient = OpenAI()\n\n\nsystem_prompt = \"\"\"Act as a music teacher. Keep your responses very short and to the point.\"\"\"\n\nuser_message = \"Explain the difference between a major and minor scale\"\n\n\nresponses = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": system_prompt\n                    }\n                ]\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": user_message\n                    }\n                ]\n            }\n        ],\n        temperature=1,\n        max_tokens=512,\n        top_p=1,\n        n = 3\n    )\n\nNow we can choose one of the responses.\n\nimport textwrap\n\ntext = responses.choices[0].message.content\n\nwrapped_text = textwrap.fill(text, width=80)\nprint(wrapped_text)\n\nA major scale has a happy, bright sound and follows the pattern: whole, whole,\nhalf, whole, whole, whole, half. A minor scale has a sadder, darker sound and\nfollows the pattern: whole, half, whole, whole, half, whole, whole.\n\n\nWe can also loop through the responses and print them all.\n\nfor i, response in enumerate(responses.choices):\n    text = response.message.content  # Changed from responses.choices[0] to response\n    wrapped_text = textwrap.fill(text, width=80)\n    print(f\"Response {i+1}:\\n{wrapped_text}\\n\")\n\nResponse 1:\nA major scale has a happy, bright sound and follows the pattern: whole, whole,\nhalf, whole, whole, whole, half. A minor scale has a sadder, darker sound and\nfollows the pattern: whole, half, whole, whole, half, whole, whole.\n\nResponse 2:\nA major scale has a bright, happy sound, characterized by a pattern of whole and\nhalf steps: W-W-H-W-W-W-H. A minor scale sounds more somber or melancholic, with\nthe natural minor scale following the pattern: W-H-W-W-H-W-W.\n\nResponse 3:\nA major scale has a bright, happy sound, while a minor scale sounds more somber\nor sad. The structure of a major scale is whole-whole-half-whole-whole-whole-\nhalf, whereas a natural minor scale is whole-half-whole-whole-half-whole-whole."
  },
  {
    "objectID": "examples/index.html",
    "href": "examples/index.html",
    "title": "Examples",
    "section": "",
    "text": "Here you will find examples of generating structured output using the OpenAI API, and using structured output to create an Anki flashcard generator.\n\nGenerating structured output\nGenerating Anki flashcards\n\n\n\n\n Back to topReuseCC BY 4.0",
    "crumbs": [
      "Example code",
      "Examples"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "We look forward to seeing your innovative approach to integrating AI technology in higher education. In your role as an AI Expert at our university, you will be instrumental in educating lecturers on AI applications for teaching and helping develop AI-powered educational tools.\n\n\nFor this round, you will:\n\nChoose one of the two assignments detailed below\nPrepare and deliver a 20-minute presentation in person, followed by a discussion. The presentation format is up to you (screen/projector are available). Language can be either English or German.\n\nBoth assignments involve working with the OpenAI API to generate Anki flashcards using structured output. The two assignment options focus on different but complementary aspects of AI in education:\n\nTeaching AI Development (Workshop Design)\nQuality Assurance for AI-Generated Content\n\nFor both assignments, we provide the code examples for generating structured output from an LLM, and for using structured output to generate Anki flashcards.\n\nStructured Output: Example code for generating structured output from an LLM\nGenerate Anki Deck: Example code for generating Anki flashcards using structured output\n\nPython code is provided here:  anki-deck-generator.zip. Installation instructions are provided in the README.md file.\nBefore reviewing the assignments, we recommend reading the background information about Anki flashcards.\n\n\n\n\n\n\nBackground: Anki Flashcards\n\n\n\n\n\n\nAnki is a powerful open-source flashcard program that uses the principles of spaced repetition and active recall to enhance learning and long-term retention. It presents flashcards at optimal intervals, adjusting the frequency of review based on the user’s performance. This is thought to ensure that information is reinforced before it is forgotten.\nOne of the key strengths of Anki is its flexibility. Users can create their own decks of flashcards tailored to their specific learning needs, or they can download pre-made decks from shared repositories covering a vast array of subjects, from languages and vocabulary to complex medical terminology.\nHowever, Anki requires a lot of manual work to create effective flashcards. In this assignment, we will explore how we can use an LLM to generate the flashcards for us.\n\n\nThe simplest type of Anki flashcard is a pair of text fields: a question and an answer (or a term and a definition).\nAnki can import flashcards from a variety of formats, including comma-separated values (CSV) files. A CSV file is a text file that uses a delimiter, e.g. a comma, to separate columns. Each line of the file is a row, and each row has of one or more columns.\nIf we have the following list of terms and definitions:\n\n\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nMetacognition\n“The ability to think about one’s own thinking processes”\n\n\nSelf-Regulated Learning\n“The process of taking control of and evaluating one’s own learning”\n\n\nExecutive Functions\n“Higher-order cognitive processes like working memory and cognitive flexibility”\n\n\nScaffolding\n“Support provided by teachers or peers to help students learn new skills”\n\n\n\nwe can save these in a CSV file:\nterm,definition\nMetacognition,\"The ability to think about one's own thinking processes\"\nSelf-Regulated Learning,\"The process of taking control of and evaluating one's own learning\"\nExecutive Functions,\"Higher-order cognitive processes like working memory and cognitive flexibility\"\nScaffolding,\"Support provided by teachers or peers to help students learn new skills\"\nIf we save the contents above in to a file, we can import them into Anki by selecting the File -&gt; Import... menu item.\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant Information\n\n\n\n\n\n\n\nYour presentation should focus on high-level concepts rather than technical implementation details. We don’t expect you to create new code, or to modify or improve the example code. Neither do you need to present a live code demo. Key areas to address include:\n\nYour conceptual approach to either:\n\nTeaching AI development to educators, or\nDeveloping quality control systems for AI-generated content\n\nYour educational philosophy and teaching methodology\nA critical analysis of AI’s potential and limitations in education\nSpecific strategies for making complex technical concepts accessible to non-technical audiences\n\n\n\n\n\nRecommended total time investment: &lt;8 hours (don’t spend more than 1 day on this) \n\n\n\n\nWhile we provide example code and technical materials, your presentation will be evaluated primarily on:\n\nEffectiveness of your teaching strategies\nUnderstanding of AI’s role in education\nAbility to communicate complex ideas to diverse audiences\n\n\n\n\n\n\n\n\nDemonstrate how you would teach lecturers to create an AI-powered Anki flashcard generator using an LLM. Give a presentation of your workshop concept.\n\n\n\n\n\n\nDetails\n\n\n\n\n\n\n\nMany lecturers want to use AI in teaching but lack technical expertise. With varying technical abilities among faculty and limited training time, we need practical, hands-on approaches that enable immediate classroom application within a 3-hour workshop format.\n\n\n\nDesign and present a concept for a 3-hour workshop teaching participants how to create an AI-powered Anki flashcard generator using the OpenAI API. Feel free to use the example code provided to help you. You may also point areas for improvement in the example code.\n\n\n\nParticipants should learn to:\n\nSet up a Python environment for working with the OpenAI API\nUse the OpenAI API to generate flashcards from educational content\nExport generated flashcards to CSV format for Anki import\n\n\n\n\nInclude:\n\nWorkshop structure and timeline\nTeaching approach for different skill levels\nHands-on exercises\nApproach to dealing with technical issues\nApproach to dealing with questions about LLMs\n\n\n\n\n\nClear teaching strategy\nTechnical accuracy\nAbility to explain complex concepts\nPractical feasibility\nEngagement with audience needs\n\n\n\n\n\n\n\n\n\nDevelop and present a system for ensuring the quality of AI-generated educational materials.\n\n\n\n\n\n\nDetails\n\n\n\n\n\n\n\nAs AI-generated educational content becomes more prevalent, ensuring its quality and effectiveness has emerged as a critical challenge. Educational institutions need robust quality control systems and clear metrics to evaluate and improve these AI-generated materials.\n\n\n\nDesign and present a concept for a system that evaluates and improves the quality of AI-generated Anki flashcards. Feel free to use the example code provided to help you. You may also present your ideas for how to improve the example code.\n\n\n\nBuild a quality control system that:\n\nEvaluates the educational effectiveness of generated flashcards\nEnsures accuracy and appropriateness of content\nProvides methods for improvement and iteration\n\n\n\n\nInclude:\n\nQuality assessment criteria\nTechnical implementation approach\nMethods for automated evaluation\nExamples of quality improvements\n\n\n\n\n\nTechnical feasibility\nQuality metrics design\nConsideration of educational effectiveness limitations of LLMs\nAbility to explain complex concepts\n\n\n\n\n\n\n\n\n\nReview both assignments\nSelect your preferred assignment\nDownload and explore the provided code\nPrepare your presentation\n\n\n\n\nIf you need any clarification or have questions, please contact: andrew.ellis@bfh.ch"
  },
  {
    "objectID": "index.html#your-task",
    "href": "index.html#your-task",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "For this round, you will:\n\nChoose one of the two assignments detailed below\nPrepare and deliver a 20-minute presentation in person, followed by a discussion. The presentation format is up to you (screen/projector are available). Language can be either English or German.\n\nBoth assignments involve working with the OpenAI API to generate Anki flashcards using structured output. The two assignment options focus on different but complementary aspects of AI in education:\n\nTeaching AI Development (Workshop Design)\nQuality Assurance for AI-Generated Content\n\nFor both assignments, we provide the code examples for generating structured output from an LLM, and for using structured output to generate Anki flashcards.\n\nStructured Output: Example code for generating structured output from an LLM\nGenerate Anki Deck: Example code for generating Anki flashcards using structured output\n\nPython code is provided here:  anki-deck-generator.zip. Installation instructions are provided in the README.md file.\nBefore reviewing the assignments, we recommend reading the background information about Anki flashcards.\n\n\n\n\n\n\nBackground: Anki Flashcards\n\n\n\n\n\n\nAnki is a powerful open-source flashcard program that uses the principles of spaced repetition and active recall to enhance learning and long-term retention. It presents flashcards at optimal intervals, adjusting the frequency of review based on the user’s performance. This is thought to ensure that information is reinforced before it is forgotten.\nOne of the key strengths of Anki is its flexibility. Users can create their own decks of flashcards tailored to their specific learning needs, or they can download pre-made decks from shared repositories covering a vast array of subjects, from languages and vocabulary to complex medical terminology.\nHowever, Anki requires a lot of manual work to create effective flashcards. In this assignment, we will explore how we can use an LLM to generate the flashcards for us.\n\n\nThe simplest type of Anki flashcard is a pair of text fields: a question and an answer (or a term and a definition).\nAnki can import flashcards from a variety of formats, including comma-separated values (CSV) files. A CSV file is a text file that uses a delimiter, e.g. a comma, to separate columns. Each line of the file is a row, and each row has of one or more columns.\nIf we have the following list of terms and definitions:\n\n\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nMetacognition\n“The ability to think about one’s own thinking processes”\n\n\nSelf-Regulated Learning\n“The process of taking control of and evaluating one’s own learning”\n\n\nExecutive Functions\n“Higher-order cognitive processes like working memory and cognitive flexibility”\n\n\nScaffolding\n“Support provided by teachers or peers to help students learn new skills”\n\n\n\nwe can save these in a CSV file:\nterm,definition\nMetacognition,\"The ability to think about one's own thinking processes\"\nSelf-Regulated Learning,\"The process of taking control of and evaluating one's own learning\"\nExecutive Functions,\"Higher-order cognitive processes like working memory and cognitive flexibility\"\nScaffolding,\"Support provided by teachers or peers to help students learn new skills\"\nIf we save the contents above in to a file, we can import them into Anki by selecting the File -&gt; Import... menu item."
  },
  {
    "objectID": "index.html#background-anki-flashcards",
    "href": "index.html#background-anki-flashcards",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "Anki is a powerful open-source flashcard program that uses the principles of spaced repetition and active recall to enhance learning and long-term retention. It presents flashcards at optimal intervals, adjusting the frequency of review based on the user’s performance. This is thought to ensure that information is reinforced before it is forgotten.\nOne of the key strengths of Anki is its flexibility. Users can create their own decks of flashcards tailored to their specific learning needs, or they can download pre-made decks from shared repositories covering a vast array of subjects, from languages and vocabulary to complex medical terminology.\nHowever, Anki requires a lot of manual work to create effective flashcards. In this assignment, we will explore how we can use an LLM to generate the flashcards for us.\n\n\nThe simplest type of Anki flashcard is a pair of text fields: a question and an answer (or a term and a definition).\nAnki can import flashcards from a variety of formats, including comma-separated values (CSV) files. A CSV file is a text file that uses a delimiter, e.g. a comma, to separate columns. Each line of the file is a row, and each row has of one or more columns.\nIf we have the following list of terms and definitions:\n\n\n\n\n\n\n\nterm\ndefinition\n\n\n\n\nMetacognition\n“The ability to think about one’s own thinking processes”\n\n\nSelf-Regulated Learning\n“The process of taking control of and evaluating one’s own learning”\n\n\nExecutive Functions\n“Higher-order cognitive processes like working memory and cognitive flexibility”\n\n\nScaffolding\n“Support provided by teachers or peers to help students learn new skills”\n\n\n\nwe can save these in a CSV file:\nterm,definition\nMetacognition,\"The ability to think about one's own thinking processes\"\nSelf-Regulated Learning,\"The process of taking control of and evaluating one's own learning\"\nExecutive Functions,\"Higher-order cognitive processes like working memory and cognitive flexibility\"\nScaffolding,\"Support provided by teachers or peers to help students learn new skills\"\nIf we save the contents above in to a file, we can import them into Anki by selecting the File -&gt; Import... menu item."
  },
  {
    "objectID": "index.html#important-information",
    "href": "index.html#important-information",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "Important Information\n\n\n\n\n\n\n\nYour presentation should focus on high-level concepts rather than technical implementation details. We don’t expect you to create new code, or to modify or improve the example code. Neither do you need to present a live code demo. Key areas to address include:\n\nYour conceptual approach to either:\n\nTeaching AI development to educators, or\nDeveloping quality control systems for AI-generated content\n\nYour educational philosophy and teaching methodology\nA critical analysis of AI’s potential and limitations in education\nSpecific strategies for making complex technical concepts accessible to non-technical audiences\n\n\n\n\n\nRecommended total time investment: &lt;8 hours (don’t spend more than 1 day on this) \n\n\n\n\nWhile we provide example code and technical materials, your presentation will be evaluated primarily on:\n\nEffectiveness of your teaching strategies\nUnderstanding of AI’s role in education\nAbility to communicate complex ideas to diverse audiences"
  },
  {
    "objectID": "index.html#assignment-1-teaching-ai-development-workshop",
    "href": "index.html#assignment-1-teaching-ai-development-workshop",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "Demonstrate how you would teach lecturers to create an AI-powered Anki flashcard generator using an LLM. Give a presentation of your workshop concept.\n\n\n\n\n\n\nDetails\n\n\n\n\n\n\n\nMany lecturers want to use AI in teaching but lack technical expertise. With varying technical abilities among faculty and limited training time, we need practical, hands-on approaches that enable immediate classroom application within a 3-hour workshop format.\n\n\n\nDesign and present a concept for a 3-hour workshop teaching participants how to create an AI-powered Anki flashcard generator using the OpenAI API. Feel free to use the example code provided to help you. You may also point areas for improvement in the example code.\n\n\n\nParticipants should learn to:\n\nSet up a Python environment for working with the OpenAI API\nUse the OpenAI API to generate flashcards from educational content\nExport generated flashcards to CSV format for Anki import\n\n\n\n\nInclude:\n\nWorkshop structure and timeline\nTeaching approach for different skill levels\nHands-on exercises\nApproach to dealing with technical issues\nApproach to dealing with questions about LLMs\n\n\n\n\n\nClear teaching strategy\nTechnical accuracy\nAbility to explain complex concepts\nPractical feasibility\nEngagement with audience needs"
  },
  {
    "objectID": "index.html#assignment-2-quality-control-for-ai-generated-content",
    "href": "index.html#assignment-2-quality-control-for-ai-generated-content",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "Develop and present a system for ensuring the quality of AI-generated educational materials.\n\n\n\n\n\n\nDetails\n\n\n\n\n\n\n\nAs AI-generated educational content becomes more prevalent, ensuring its quality and effectiveness has emerged as a critical challenge. Educational institutions need robust quality control systems and clear metrics to evaluate and improve these AI-generated materials.\n\n\n\nDesign and present a concept for a system that evaluates and improves the quality of AI-generated Anki flashcards. Feel free to use the example code provided to help you. You may also present your ideas for how to improve the example code.\n\n\n\nBuild a quality control system that:\n\nEvaluates the educational effectiveness of generated flashcards\nEnsures accuracy and appropriateness of content\nProvides methods for improvement and iteration\n\n\n\n\nInclude:\n\nQuality assessment criteria\nTechnical implementation approach\nMethods for automated evaluation\nExamples of quality improvements\n\n\n\n\n\nTechnical feasibility\nQuality metrics design\nConsideration of educational effectiveness limitations of LLMs\nAbility to explain complex concepts"
  },
  {
    "objectID": "index.html#next-steps",
    "href": "index.html#next-steps",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "Review both assignments\nSelect your preferred assignment\nDownload and explore the provided code\nPrepare your presentation"
  },
  {
    "objectID": "index.html#questions",
    "href": "index.html#questions",
    "title": "AI Expert Position Assessment - Round 2",
    "section": "",
    "text": "If you need any clarification or have questions, please contact: andrew.ellis@bfh.ch"
  },
  {
    "objectID": "notebooks/examples.html",
    "href": "notebooks/examples.html",
    "title": "Round 2: Assignments",
    "section": "",
    "text": "from dotenv import load_dotenv\nfrom openai import OpenAI \nimport textwrap\n\n\nload_dotenv()\n\nTrue\n\n\n\nclient = OpenAI()\n\n\nfrom IPython.display import Markdown, display\n\ndef generate_response(user_message,\n        model=\"gpt-4o\", \n        system_prompt=\"You are a helpful assistant.\",  \n        temperature=1.0, \n        top_p=1.0, \n        max_tokens=2048):\n                      \n    response = client.chat.completions.create(\n        model=model,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": system_prompt\n                    }\n                ]\n            },\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": user_message\n                    }\n                ]\n            }\n        ],\n        temperature=temperature,\n        max_tokens=max_tokens,\n        top_p=top_p\n    )\n    # Get the response text\n    text = response.choices[0].message.content\n    \n    # Display as markdown instead of plain text\n    display(Markdown(text))\n\n\ngenerate_response(user_message=\"Explain the harmonic series\")\n\nThe harmonic series is the infinite series defined as the sum of the reciprocals of the positive integers:\n[ H = _{n=1}^{} = 1 + + + + + ]\nDespite each of its terms becoming smaller and smaller as ( n ) increases, the harmonic series diverges, meaning its sum grows without bound. This can be shown through several methods, one classical approach being a comparison test. For example, you can compare the harmonic series to a related series formed by grouping terms:\n[ 1 + () + ( + ) + ( + + + ) + ]\nEach group ( n ) (where ( n )) contains ( 2^{n-1} ) terms, each of which is greater than or equal to ( ), leading to the inequality:\n[ 1 + + ( + ) + ( + + + ) + &gt; 1 + + + + ]\n[ = 1 + + + + ]\nEach additional block sums to at least ( ), demonstrating that the harmonic series’ sum can exceed any finite number as more terms and further groups are added.\nFurthermore, the ( n )-th partial sum of the harmonic series, denoted ( H_n = 1 + + + + ), is approximately logarithmic in growth:\n[ H_n (n) + ]\nwhere ( ) is the Euler-Mascheroni constant, approximately 0.577. The term ( (n) ) shows how the harmonic series diverges very slowly.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/generate-anki-deck.html",
    "href": "notebooks/generate-anki-deck.html",
    "title": "Generate Anki Flashcards",
    "section": "",
    "text": "Instructions:\n\nCreate a new virtual environment:\n\npython -m venv .venv\n\nActivate the environment:\n\nsource .venv/bin/activate\n\nInstall the dependencies:\n\npip install -r requirements.txt\n\nCreate a .env file and add your OpenAI API key:\n\nOPENAI_API_KEY=&lt;your-openai-api-key&gt;",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/generate-anki-deck.html#setup",
    "href": "notebooks/generate-anki-deck.html#setup",
    "title": "Generate Anki Flashcards",
    "section": "",
    "text": "Instructions:\n\nCreate a new virtual environment:\n\npython -m venv .venv\n\nActivate the environment:\n\nsource .venv/bin/activate\n\nInstall the dependencies:\n\npip install -r requirements.txt\n\nCreate a .env file and add your OpenAI API key:\n\nOPENAI_API_KEY=&lt;your-openai-api-key&gt;",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/generate-anki-deck.html#openai-client-and-pydantic-models",
    "href": "notebooks/generate-anki-deck.html#openai-client-and-pydantic-models",
    "title": "Generate Anki Flashcards",
    "section": "OpenAI client and pydantic models",
    "text": "OpenAI client and pydantic models\n\nimport os\nimport csv\nfrom dotenv import load_dotenv\nfrom openai import OpenAI \nfrom textwrap import dedent \n\n# Import Pydantic for data validation and typing\nfrom pydantic import BaseModel, Field\nfrom typing import List\n\n\nload_dotenv()\n\nTrue\n\n\nIf you want to see the API key, you can uncomment the following line:\n\n# print(os.getenv(\"OPENAI_API_KEY\"))\n\nInitialize OpenAI client:\n\nclient = OpenAI()\n\nDefine the AnkiFlashcard and AnkiDeck pydantic models:\n\nAnkiFlashcard: Represents a single flashcard with a question, answer, and tags\nAnkiDeck: Represents a collection of flashcards with a deck name\n\n\nclass AnkiFlashcard(BaseModel):\n    \"\"\"\n    Model representing a single Anki flashcard with question, answer, and tags.\n    \"\"\"\n    # Define required fields with descriptions\n    question: str = Field(..., description=\"The front side of the flashcard containing the question\")\n    answer: str = Field(..., description=\"The back side of the flashcard containing the answer\")\n    tags: List[str] = Field(..., description=\"List of tags associated with the flashcard\")\n\nclass AnkiDeck(BaseModel):\n    \"\"\"\n    Model representing a complete Anki deck containing multiple flashcards.\n    \"\"\"\n    # Define required fields with descriptions\n    cards: List[AnkiFlashcard] = Field(..., description=\"List of flashcards in the deck\")\n    deck_name: str = Field(..., description=\"Name of the Anki deck\")",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/generate-anki-deck.html#function-to-generate-structured-flashcards",
    "href": "notebooks/generate-anki-deck.html#function-to-generate-structured-flashcards",
    "title": "Generate Anki Flashcards",
    "section": "Function to generate structured flashcards",
    "text": "Function to generate structured flashcards\nThe function takes a text input and generates a structured deck of Anki flashcards using the OpenAI API:\n\nValidates that the requested number of cards is at least 1\nMakes an API call to OpenAI with:\n\nSystem prompt that defines the flashcard creation task\nUser prompt containing the input text\nResponse format set to our AnkiDeck Pydantic model\n\nReturns the parsed response as a validated AnkiDeck object\n\n\ndef generate_deck(text: str, deck_name: str, num_cards: int = 5, model: str = \"gpt-4o-mini\") -&gt; AnkiDeck:\n    \"\"\"\n    Generate structured flashcards using GPT-4o or GPT-4o-mini with enforced Pydantic model output.\n    \n    Args:\n        text (str): The input text to generate flashcards from\n        deck_name (str): Name for the Anki deck\n        num_cards (int): Number of flashcards to generate (default: 5)\n        \n    Returns:\n        AnkiDeck: A structured deck of flashcards with validation\n        \n    Raises:\n        ValueError: If num_cards is less than 1\n    \"\"\"\n    # Validate input\n    if num_cards &lt; 1:\n        raise ValueError(\"Number of cards must be at least 1\")\n    \n    # Make API call with structured output format\n    completion = client.beta.chat.completions.parse(\n        model=model,\n        messages=[\n            {\n                \"role\": \"system\",\n                \"content\": dedent(f\"\"\"\n                    You are an expert at creating Anki flashcards. Your task is to:\n                    1. Read the provided text\n                    2. Create {num_cards} Anki flashcards that cover the main concepts\n                    3. Add relevant tags to each flashcard\n                    4. Structure the output as an Anki deck with the name \"{deck_name}\".\"\"\")\n            },\n            {\n                \"role\": \"user\",\n                \"content\": f\"Please create Anki flashcards for the following text: {text}\"\n            }\n        ],\n        response_format=AnkiDeck,\n    )\n    \n    # Return the parsed response\n    return completion.choices[0].message.parsed",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/generate-anki-deck.html#test-the-function",
    "href": "notebooks/generate-anki-deck.html#test-the-function",
    "title": "Generate Anki Flashcards",
    "section": "Test the function",
    "text": "Test the function\nWe’ll first test the function with the baroque essay:\n\nwith open(\"assets/essays/baroque.md\", \"r\") as file:\n    baroque = file.read()\n\nprint the first 5 lines of the baroque essay:\n\nprint('\\n'.join(baroque.splitlines()[:5]))\n\n# The Baroque Era: Birth of Musical Drama (1600-1750)\n\nThe Baroque era represents one of the most transformative periods in Western musical history, marked by dramatic innovations in both compositional technique and musical expression. This period witnessed the birth of opera, the development of instrumental programs, and the establishment of musical practices that would influence composers for centuries to come.\n\n## The Birth of Opera and Dramatic Expression\n\n\nCall the function with the baroque essay and print the resulting deck. We are using the gpt-4o-mini model to generate a deck containing 5 flashcards.\n\nbaroque_deck = generate_deck(baroque, \"Baroque Period\", num_cards=5, model=\"gpt-4o-mini\")\n\n\nbaroque_deck\n\nAnkiDeck(cards=[AnkiFlashcard(question='What significant musical genre was born during the Baroque era?', answer='Opera was born during the Baroque era, particularly through the efforts of the Camerata in Florence.', tags=['Baroque Era', 'Opera', 'Musical Innovation']), AnkiFlashcard(question='Which composition is considered the first masterpiece of opera?', answer=\"Monteverdi's 'L'Orfeo' (1607) is regarded as the first masterpiece of opera.\", tags=['Baroque Era', \"L'Orfeo\", 'Opera']), AnkiFlashcard(question='What musical practice was established during the Baroque era to support harmonic structure?', answer='The practice of basso continuo was established, providing a bass line with chord symbols as the harmonic foundation.', tags=['Baroque Era', 'Basso Continuo', 'Harmony']), AnkiFlashcard(question='Who are two significant composers associated with the Baroque period?', answer='J.S. Bach and Jean-Baptiste Lully were significant composers of the Baroque period.', tags=['Baroque Era', 'J.S. Bach', 'Jean-Baptiste Lully']), AnkiFlashcard(question=\"What impact did the Baroque era have on Western music's future?\", answer='The Baroque era established functional harmony and important musical forms that influenced Classical and Romantic music.', tags=['Baroque Era', 'Musical Legacy', 'Functional Harmony'])], deck_name='Baroque Period')\n\n\nYou can also access the individual cards in the deck:\n\nbaroque_deck.cards\n\n[AnkiFlashcard(question='What significant musical genre was born during the Baroque era?', answer='Opera was born during the Baroque era, particularly through the efforts of the Camerata in Florence.', tags=['Baroque Era', 'Opera', 'Musical Innovation']),\n AnkiFlashcard(question='Which composition is considered the first masterpiece of opera?', answer=\"Monteverdi's 'L'Orfeo' (1607) is regarded as the first masterpiece of opera.\", tags=['Baroque Era', \"L'Orfeo\", 'Opera']),\n AnkiFlashcard(question='What musical practice was established during the Baroque era to support harmonic structure?', answer='The practice of basso continuo was established, providing a bass line with chord symbols as the harmonic foundation.', tags=['Baroque Era', 'Basso Continuo', 'Harmony']),\n AnkiFlashcard(question='Who are two significant composers associated with the Baroque period?', answer='J.S. Bach and Jean-Baptiste Lully were significant composers of the Baroque period.', tags=['Baroque Era', 'J.S. Bach', 'Jean-Baptiste Lully']),\n AnkiFlashcard(question=\"What impact did the Baroque era have on Western music's future?\", answer='The Baroque era established functional harmony and important musical forms that influenced Classical and Romantic music.', tags=['Baroque Era', 'Musical Legacy', 'Functional Harmony'])]\n\n\nPrint all the cards in the deck:\n\nfor card in baroque_deck.cards:\n    print(f\"Question: {card.question}\")\n    print(f\"Answer: {card.answer}\")\n    print(f\"Tags: {', '.join(card.tags)}\")\n    print(\"-\" * 20)\n\nQuestion: What significant musical genre was born during the Baroque era?\nAnswer: Opera was born during the Baroque era, particularly through the efforts of the Camerata in Florence.\nTags: Baroque Era, Opera, Musical Innovation\n--------------------\nQuestion: Which composition is considered the first masterpiece of opera?\nAnswer: Monteverdi's 'L'Orfeo' (1607) is regarded as the first masterpiece of opera.\nTags: Baroque Era, L'Orfeo, Opera\n--------------------\nQuestion: What musical practice was established during the Baroque era to support harmonic structure?\nAnswer: The practice of basso continuo was established, providing a bass line with chord symbols as the harmonic foundation.\nTags: Baroque Era, Basso Continuo, Harmony\n--------------------\nQuestion: Who are two significant composers associated with the Baroque period?\nAnswer: J.S. Bach and Jean-Baptiste Lully were significant composers of the Baroque period.\nTags: Baroque Era, J.S. Bach, Jean-Baptiste Lully\n--------------------\nQuestion: What impact did the Baroque era have on Western music's future?\nAnswer: The Baroque era established functional harmony and important musical forms that influenced Classical and Romantic music.\nTags: Baroque Era, Musical Legacy, Functional Harmony\n--------------------",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/generate-anki-deck.html#write-deck-to-a-csv-file",
    "href": "notebooks/generate-anki-deck.html#write-deck-to-a-csv-file",
    "title": "Generate Anki Flashcards",
    "section": "Write deck to a CSV file",
    "text": "Write deck to a CSV file\nWe’ll create a function to write the deck to a CSV file. The function takes an AnkiDeck object and a path to save the CSV file. It ensures the directory exists and writes the deck to a CSV file with the following columns: Question, Answer, Tags.\n\ndef write_deck_to_csv(deck: AnkiDeck, output_path: str) -&gt; None:\n    \"\"\"\n    Save an Anki deck to a CSV file.\n    \n    Args:\n        deck (AnkiDeck): The deck of flashcards to save\n        output_path (str): Path where the CSV file should be saved\n    \"\"\"\n    # Ensure the directory exists\n    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n    \n    with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n        writer = csv.writer(csvfile)\n        # Write header row\n        writer.writerow(['Question', 'Answer', 'Tags'])\n        # Write each flashcard as a row in the CSV\n        for card in deck.cards:\n            writer.writerow([card.question, card.answer, ', '.join(card.tags)])\n    print(f\"Successfully saved deck '{deck.deck_name}' to {output_path}\")\n\nSave the baroque deck to a CSV file:\n\nwrite_deck_to_csv(baroque_deck, 'assets/flashcards/baroque-flashcards.csv')\n\nSuccessfully saved deck 'Baroque Period' to assets/flashcards/baroque-flashcards.csv",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/generate-anki-deck.html#process-all-markdown-files-in-essays",
    "href": "notebooks/generate-anki-deck.html#process-all-markdown-files-in-essays",
    "title": "Generate Anki Flashcards",
    "section": "Process all markdown files in essays",
    "text": "Process all markdown files in essays\nNow we’ll process all the markdown files in the essays directory and generate flashcards for each one.\nFor simplicity, we will loop over all files. This could be made more efficient by using a function that takes a directory as an argument and returns a list of decks.\nFirst, we’ll import the glob module for finding pathnames matching a pattern.\n\nimport glob\n\nFind all the markdown files in the essays directory:\n\nessay_files = glob.glob(\"assets/essays/*.md\")\nessay_files\n\n['assets/essays/classical.md',\n 'assets/essays/modern.md',\n 'assets/essays/baroque.md',\n 'assets/essays/romantic.md']\n\n\nNow we’ll loop over all the files and generate flashcards for each one.\n\nfor essay_file in essay_files:\n    # Get the base filename without extension to use as deck name\n    base_name = os.path.basename(essay_file).replace('.md', '')\n    deck_name = base_name.replace('-', ' ').title()\n    \n    print(f\"Processing {deck_name}...\")\n    \n    # Read the essay content\n    with open(essay_file, \"r\") as file:\n        content = file.read()\n    \n    # Generate deck\n    deck = generate_deck(content, deck_name, num_cards=5, model=\"gpt-4o-mini\")\n    \n    # Save to CSV\n    output_path = f'assets/flashcards/{base_name}-flashcards.csv'\n    write_deck_to_csv(deck, output_path)\n    \n    print(f\"Saved flashcards to {output_path}\")\n\nProcessing Classical...\nSuccessfully saved deck 'Classical' to assets/flashcards/classical-flashcards.csv\nSaved flashcards to assets/flashcards/classical-flashcards.csv\nProcessing Modern...\nSuccessfully saved deck 'Modern' to assets/flashcards/modern-flashcards.csv\nSaved flashcards to assets/flashcards/modern-flashcards.csv\nProcessing Baroque...\nSuccessfully saved deck 'Baroque' to assets/flashcards/baroque-flashcards.csv\nSaved flashcards to assets/flashcards/baroque-flashcards.csv\nProcessing Romantic...\nSuccessfully saved deck 'Romantic' to assets/flashcards/romantic-flashcards.csv\nSaved flashcards to assets/flashcards/romantic-flashcards.csv",
    "crumbs": [
      "Example code",
      "Generate Anki Flashcards"
    ]
  },
  {
    "objectID": "notebooks/spacy.html",
    "href": "notebooks/spacy.html",
    "title": "Round 2: Assignments",
    "section": "",
    "text": "import spacy\n\n\n\n# Load the German SpaCy model\nnlp = spacy.load(\"de_core_news_md\")\n\n\n\n# Analyze the sentence\ntext = \"\"\"Die Familie, die sehr wohlhabend war, lebte in einem grossen Haus. \nDas Haus stand inmitten eines weitläufigen Gartens. Es war bekannt für seine \nprächtige Fassade und die grosszügigen\"\"\"\n\n\n\ndoc = nlp(text)\n\n\n\n# Dependency parsing and POS tagging\nfor token in doc:\n    print(f\"{token.text:15} {token.pos_:10} {token.dep_:10} {token.head.text}\")\n\nDie             DET        nk         Familie\nFamilie         NOUN       sb         lebte\n,               PUNCT      punct      Familie\ndie             PRON       sb         war\nsehr            ADV        mo         wohlhabend\nwohlhabend      ADV        pd         war\nwar             AUX        rc         Familie\n,               PUNCT      punct      lebte\nlebte           VERB       ROOT       lebte\nin              ADP        mo         lebte\neinem           DET        nk         Haus\ngrossen         ADJ        nk         Haus\nHaus            NOUN       nk         in\n.               PUNCT      punct      lebte\n\n               SPACE      dep        .\nDas             DET        nk         Haus\nHaus            NOUN       sb         stand\nstand           VERB       ROOT       stand\ninmitten        ADP        mo         stand\neines           DET        nk         Gartens\nweitläufigen    ADJ        nk         Gartens\nGartens         NOUN       nk         inmitten\n.               PUNCT      punct      stand\nEs              PRON       sb         war\nwar             AUX        ROOT       war\nbekannt         ADV        pd         war\nfür             ADP        mo         bekannt\nseine           DET        nk         Fassade\n\n               SPACE      dep        seine\nprächtige       ADJ        nk         Fassade\nFassade         NOUN       nk         für\nund             CCONJ      cd         Fassade\ndie             DET        nk         grosszügigen\ngrosszügigen    ADJ        cj         und\n\n\n\n\n# Suggest similar words or predict based on context\nsimilar_words = [word.text for word in doc if word.pos_ == \"NOUN\"]\nprint(\"Potential continuations:\", similar_words)\n\nPotential continuations: ['Familie', 'Haus', 'Haus', 'Gartens', 'Fassade']\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "notebooks/test-structured-output.html",
    "href": "notebooks/test-structured-output.html",
    "title": "Round 2: Assignments",
    "section": "",
    "text": "import os\nfrom dotenv import load_dotenv\nfrom pydantic import BaseModel\nfrom openai import OpenAI\n\n\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Create OpenAI client with API key\nclient = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n\n\n\nclass CalendarEvent(BaseModel):\n    name: str\n    date: str\n    participants: list[str]\n\n\n\ncompletion = client.beta.chat.completions.parse(\n    model=\"gpt-4o-2024-08-06\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n        {\"role\": \"user\", \"content\": \"Alice and Bob are going to a science fair on Friday.\"},\n    ],\n    response_format=CalendarEvent,\n)\n\nevent = completion.choices[0].message.parsed\n\n\nevent\n\nCalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])\n\n\n\nevent.name\n\n'Science Fair'\n\n\n\nimport csv\n\n# Create a list of dictionaries from the event object\nevent_data = [event.__dict__]\n\n# Open a CSV file for writing\nwith open('events.csv', 'w', newline='') as csvfile:\n    fieldnames = event_data[0].keys()\n    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n\n    # Write the header\n    writer.writeheader()\n\n    # Write the data\n    writer.writerows(event_data)\n\n\nevent\n\nCalendarEvent(name='Science Fair', date='Friday', participants=['Alice', 'Bob'])\n\n\n\n\n\n Back to top"
  }
]